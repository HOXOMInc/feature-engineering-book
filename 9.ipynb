{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 19)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_df = pd.read_json('data/mag_papers/mag_papers_0.txt', lines=True)\n",
    "model_df = model_df.head(20000)\n",
    "\n",
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10399, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = model_df[model_df.lang == 'en']\\\n",
    "    .drop_duplicates(subset = 'title', keep = 'first')\\\n",
    "    .drop(['doc_type', 'doi', 'id', 'issue', 'lang', 'n_citation', 'page_end', 'page_start', 'publisher', \n",
    "              'references', 'url', 'venue', 'volume'], axis=1)\n",
    "\n",
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of first feature array:  3787893471\n"
     ]
    }
   ],
   "source": [
    "def feature_array(x):\n",
    "    df_list = [pd.DataFrame([[1] * len(val)], columns=val, index=[index])\n",
    "                  if isinstance(val, list) else pd.DataFrame(index=[index])\n",
    "                  for val, index in zip(x.values, x.index)]\n",
    "    \n",
    "    feature_df = pd.concat(df_list, axis=1, sort=True)\n",
    "    return feature_df.fillna(0)\n",
    "\n",
    "year_features = pd.get_dummies(model_df[\"year\"].astype('category'))\n",
    "fos_features = feature_array(model_df['fos'])\n",
    "first_features = fos_features.join(year_features).T\n",
    "\n",
    "from sys import getsizeof\n",
    "print('Size of first feature array: ', getsizeof(first_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def item_collab_filter(features_df):\n",
    "    return pd.DataFrame([[1 - cosine(col_val1, col_val2)\n",
    "                                     for col_val1 in features_df.T.values] for col_val2 in features_df.T.values],\n",
    "                                     index = features_df.columns, columns = features_df.columns)\n",
    "\n",
    "first_items = item_collab_filter(first_features.loc[:, 0:1000])\n",
    "\n",
    "first_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set()\n",
    "ax = sns.heatmap(first_items.fillna(0), \n",
    "                 vmin=0, vmax=1, \n",
    "                 cmap=\"YlGnBu\", \n",
    "                 xticklabels=250, yticklabels=250)\n",
    "ax.tick_params(labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_recommender(paper_ix, items_df):\n",
    "    print('Based on the paper: \\nindex = ', paper_ix)\n",
    "    print(model_df.iloc[paper_ix])\n",
    "    top_results = items_df.loc[paper_ix].sort_values(ascending=False).head(4)\n",
    "    print('\\nTop three results: ')\n",
    "    order = 1\n",
    "    for i in top_results.index.tolist()[-3:]:\n",
    "        print(order,'. Paper index = ', i)\n",
    "        print('Similarity score: ', top_results[i])\n",
    "        print(model_df.iloc[i], '\\n')\n",
    "        if order < 5: order += 1\n",
    "            \n",
    "paper_recommender(2, first_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_min = model_df['year'].min()\n",
    "year_max = model_df['year'].max()\n",
    "\n",
    "print(\"Year spread: \", year_min,\" - \", year_max)\n",
    "print(\"Quantile spread:\\n\", model_df['year'].quantile([0.25, 0.5, 0.75]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "model_df['year'].hist(ax=ax, bins= year_max - year_min)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_xlabel('Year Count', fontsize=12)\n",
    "ax.set_ylabel('Occurrence', fontsize=12)\n",
    "\n",
    "bins = int(round((year_max - year_min) / 10))\n",
    "\n",
    "temp_df = pd.DataFrame(index = model_df.index)\n",
    "temp_df['yearBinned'] = pd.cut(model_df['year'].tolist(), bins, precision = 0)\n",
    "\n",
    "X_yrs = pd.get_dummies(temp_df['yearBinned'])\n",
    "X_yrs.columns.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "X_yrs.sum().plot.bar(ax = ax)\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.set_xlabel('Binned Years', fontsize=12)\n",
    "ax.set_ylabel('Counts', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fos = fos_features.values\n",
    "\n",
    "print('Our pandas Series, in bytes: ', getsizeof(fos_features))\n",
    "print('Our hashed numpy array, in bytes: ', getsizeof(X_fos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_features = np.append(X_fos, X_yrs, axis = 1)\n",
    "\n",
    "print(\"The power of feature engineering saves us, in bytes: \",\n",
    "         getsizeof(first_features) - getsizeof(second_features))\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def piped_collab_filter(features_matrix, index, top_n):\n",
    "    item_similarities = \\\n",
    "        1 - cosine_similarity(features_matrix[index:index+1],\n",
    "                              features_matrix).flatten()\n",
    "    related_indices = \\\n",
    "        [i for i in item_similarities.argsort()[::-1] if i != index]\n",
    "    return [(index, item_similarities[index]) for index in related_indices][0:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_recommender(items_df, paper_ix, top_n):\n",
    "    if paper_ix in model_df.index:\n",
    "        print('Based on the paper:')\n",
    "        print('Paper index = ', model_df.loc[paper_ix].name)\n",
    "        print('Title :', model_df.loc[paper_ix]['title'])\n",
    "        print('FOS :', model_df.loc[paper_ix]['fos'])\n",
    "        print('Year :', model_df.loc[paper_ix]['year'])\n",
    "        print('Abstract :', model_df.loc[paper_ix]['abstract'])\n",
    "        print('Authors :', model_df.loc[paper_ix]['authors'], '\\n')\n",
    "\n",
    "        array_ix = model_df.index.get_loc(paper_ix)\n",
    "        top_results = piped_collab_filter(items_df, array_ix, top_n)\n",
    "        print('\\nTop',top_n,'results: ')\n",
    "\n",
    "        order = 1\n",
    "        for i in range(len(top_results)):\n",
    "            print(order,'. Paper index = ', model_df.iloc[top_results[i][0]].name)\n",
    "            print('Similarity score: ', top_results[i][1])\n",
    "            print('Title :', model_df.iloc[top_results[i][0]]['title'])\n",
    "            print('FOS :', model_df.iloc[top_results[i][0]]['fos'])\n",
    "            print('Year :', model_df.iloc[top_results[i][0]]['year'])\n",
    "            print('Abstract :', model_df.iloc[top_results[i][0]]['abstract'])\n",
    "            print('Authors :', model_df.iloc[top_results[i][0]]['authors'], '\\n')\n",
    "            if order < top_n: order += 1\n",
    "                    \n",
    "    else:\n",
    "        print('Whoops! Choose another paper. Try something from here: \\n', model_df.index[100:200])\n",
    "\n",
    "paper_recommender(second_features, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.loc[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.iloc[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.index.get_loc(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df = model_df.fillna('None')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "X_abstract = vectorizer.fit_transform(filled_df['abstract'])\n",
    "\n",
    "third_features = np.append(second_features, X_abstract.toarray(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list = []\n",
    "\n",
    "for row in filled_df.itertuples():\n",
    "    if isinstance(row.authors, str):\n",
    "        y = {'None': row.Index}\n",
    "    if isinstance(row.authors, list):\n",
    "        y = dict.fromkeys(row.authors[0].values(), row.Index)\n",
    "\n",
    "    authors_list.append(y)\n",
    "\n",
    "authors_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=False)\n",
    "D = authors_list\n",
    "X_authors = v.fit_transform(D)\n",
    "fourth_features = np.append(third_features, X_authors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_recommender(fourth_features, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
